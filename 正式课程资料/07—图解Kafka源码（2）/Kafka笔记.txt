如何去看Kafka的源码的？
1. 搞懂它的通信的框架/原理
   Hadoop(hadoop RPC) hbase(hadoop RPC) spark(Nettty) flink(akka)
   kafka: NIO(socket) 我们本来就懂
2. 场景去驱动
   2.1 生产者发送数据

   2.2 服务端接收数据（）
   	   1）元数据的管理
   	   2）副本数据的同步
   	   3) 集群的管理
   	   .......
   2.3 消费者消费数据

   开源的技术 ->官方文档写得都还不错 (Spark/flink) 
               examples（代码案例）

3. 第一个场景：写数据的流程（生产者发送数据的流程）

1. 从一个Demo里面的一个场景入手
2. 给大家回忆了一下生产者发送数据的流程
3. Producer的初始化的流程
4. 看了元数据信息的数据结构
5. 生产者发送消息的流程初探
6. 如何获取的元数据？
7. 根据元数据信息 决定当前的这个消息应该要发送到哪个分区上面？

听我说：
代码结构

append：高并发的方法，同时我们还要保证线程安全！！

HDFS的源码的时候：分段加锁 -》缩小锁的粒度， 肯定是在保证线程安全的情况
public void append(xx){
	xxxx;//线程安全，读写分离的思想
	synchronized(){

	};
	xxxx;
	synchronized(){

	};

}










